{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1ZEpn_1yVRvW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "CZam2qTLc2XY"
   },
   "outputs": [],
   "source": [
    "# Use it when using google collab to train, saves model to drive automatically once done\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Inserting training data (matrix) to colab\n",
    "<!-- ![dataset_insertion_colab.png](attachment:dataset_insertion_colab.png) -->\n",
    "<img src=\"imgs/dataset_insertion_colab.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use provided GPU from colab\n",
    "<!-- ![change_runtime_colab.png](attachment:change_runtime_colab.png) -->\n",
    "<img src=\"imgs/change_runtime_colab.png\">\n",
    "Select \"GPU\" from Hardware accelerator\n",
    "<img src=\"imgs/change_runtime_colab2.png\" style=\"width:300px;height:200px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andyko/Desktop/EEG_Classification/trainings\n",
      "/Users/andyko/Desktop/EEG_Classification\n"
     ]
    }
   ],
   "source": [
    "# Keep the original path\n",
    "org_cwd = os.getcwd()\n",
    "print(org_cwd)\n",
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "7lYkqmr_VRvZ",
    "outputId": "c8d3f81e-a7be-4009-a284-04cac74ef97a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    216\n",
      "2.0    216\n",
      "1.0    216\n",
      "Name: Label, dtype: int64\n",
      "df shape: (648, 989)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag1_mean_0</th>\n",
       "      <th>lag1_mean_1</th>\n",
       "      <th>lag1_mean_2</th>\n",
       "      <th>lag1_mean_3</th>\n",
       "      <th>lag1_mean_d_h2h1_0</th>\n",
       "      <th>lag1_mean_d_h2h1_1</th>\n",
       "      <th>lag1_mean_d_h2h1_2</th>\n",
       "      <th>lag1_mean_d_h2h1_3</th>\n",
       "      <th>lag1_mean_q1_0</th>\n",
       "      <th>lag1_mean_q1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>freq_669_3</th>\n",
       "      <th>freq_679_3</th>\n",
       "      <th>freq_689_3</th>\n",
       "      <th>freq_699_3</th>\n",
       "      <th>freq_709_3</th>\n",
       "      <th>freq_720_3</th>\n",
       "      <th>freq_730_3</th>\n",
       "      <th>freq_740_3</th>\n",
       "      <th>freq_750_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-37.277174</td>\n",
       "      <td>-43.030969</td>\n",
       "      <td>-36.447629</td>\n",
       "      <td>-35.684127</td>\n",
       "      <td>-15.007371</td>\n",
       "      <td>-1.645471</td>\n",
       "      <td>1.909458</td>\n",
       "      <td>-10.250657</td>\n",
       "      <td>-30.173763</td>\n",
       "      <td>-39.916087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.014673</td>\n",
       "      <td>0.016323</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.023877</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>0.010377</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-36.642161</td>\n",
       "      <td>-39.056745</td>\n",
       "      <td>-26.281063</td>\n",
       "      <td>-40.255439</td>\n",
       "      <td>-2.241697</td>\n",
       "      <td>-12.631036</td>\n",
       "      <td>-5.477559</td>\n",
       "      <td>12.076263</td>\n",
       "      <td>-47.894014</td>\n",
       "      <td>-25.070973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017032</td>\n",
       "      <td>0.020773</td>\n",
       "      <td>0.008015</td>\n",
       "      <td>0.026345</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>0.030342</td>\n",
       "      <td>0.020967</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.032048</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-40.229463</td>\n",
       "      <td>-63.108915</td>\n",
       "      <td>-67.984208</td>\n",
       "      <td>-72.194004</td>\n",
       "      <td>-0.341225</td>\n",
       "      <td>6.349947</td>\n",
       "      <td>-4.684524</td>\n",
       "      <td>22.157984</td>\n",
       "      <td>-36.495415</td>\n",
       "      <td>-65.410248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>0.024158</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>0.020656</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>0.009691</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.013673</td>\n",
       "      <td>0.018705</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-37.450039</td>\n",
       "      <td>-39.011419</td>\n",
       "      <td>-35.203550</td>\n",
       "      <td>-37.985609</td>\n",
       "      <td>-0.184593</td>\n",
       "      <td>-2.599875</td>\n",
       "      <td>-2.107257</td>\n",
       "      <td>-4.667253</td>\n",
       "      <td>-39.540556</td>\n",
       "      <td>-38.890191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>0.020171</td>\n",
       "      <td>0.018735</td>\n",
       "      <td>0.008070</td>\n",
       "      <td>0.022522</td>\n",
       "      <td>0.025040</td>\n",
       "      <td>0.035756</td>\n",
       "      <td>0.017217</td>\n",
       "      <td>0.012021</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-31.236584</td>\n",
       "      <td>-40.498620</td>\n",
       "      <td>-30.246655</td>\n",
       "      <td>-29.695176</td>\n",
       "      <td>-7.886850</td>\n",
       "      <td>7.877147</td>\n",
       "      <td>-1.172290</td>\n",
       "      <td>-5.199914</td>\n",
       "      <td>-26.230491</td>\n",
       "      <td>-48.784865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013128</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>0.027893</td>\n",
       "      <td>0.026951</td>\n",
       "      <td>0.022054</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.018158</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>-39.242498</td>\n",
       "      <td>-45.737576</td>\n",
       "      <td>-34.980090</td>\n",
       "      <td>-39.244412</td>\n",
       "      <td>18.515956</td>\n",
       "      <td>9.856033</td>\n",
       "      <td>-0.110216</td>\n",
       "      <td>16.329277</td>\n",
       "      <td>-69.083018</td>\n",
       "      <td>-57.004967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050628</td>\n",
       "      <td>0.051594</td>\n",
       "      <td>0.025037</td>\n",
       "      <td>0.012807</td>\n",
       "      <td>0.023609</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>-24.606315</td>\n",
       "      <td>-33.268484</td>\n",
       "      <td>-29.241134</td>\n",
       "      <td>-28.847063</td>\n",
       "      <td>-5.959537</td>\n",
       "      <td>4.258647</td>\n",
       "      <td>-0.051484</td>\n",
       "      <td>-4.038128</td>\n",
       "      <td>-19.911037</td>\n",
       "      <td>-35.485516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.009808</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>-26.876310</td>\n",
       "      <td>-35.773260</td>\n",
       "      <td>-25.528787</td>\n",
       "      <td>-26.643508</td>\n",
       "      <td>-0.760498</td>\n",
       "      <td>-0.923390</td>\n",
       "      <td>-3.411059</td>\n",
       "      <td>0.451387</td>\n",
       "      <td>-23.806253</td>\n",
       "      <td>-34.942615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010003</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.014943</td>\n",
       "      <td>0.014015</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>-25.517000</td>\n",
       "      <td>-37.471278</td>\n",
       "      <td>-27.008659</td>\n",
       "      <td>-26.074239</td>\n",
       "      <td>1.494077</td>\n",
       "      <td>-2.046352</td>\n",
       "      <td>0.591996</td>\n",
       "      <td>-0.201772</td>\n",
       "      <td>-19.449005</td>\n",
       "      <td>-35.719971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034118</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>0.026596</td>\n",
       "      <td>0.030456</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.004276</td>\n",
       "      <td>0.013569</td>\n",
       "      <td>0.036147</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>-8.482512</td>\n",
       "      <td>-34.694453</td>\n",
       "      <td>-26.026519</td>\n",
       "      <td>-9.582047</td>\n",
       "      <td>-28.916717</td>\n",
       "      <td>0.389423</td>\n",
       "      <td>3.632897</td>\n",
       "      <td>-26.254541</td>\n",
       "      <td>25.596159</td>\n",
       "      <td>-36.627040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010696</td>\n",
       "      <td>0.011209</td>\n",
       "      <td>0.009125</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.004840</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.005150</td>\n",
       "      <td>0.016070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>648 rows × 989 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     lag1_mean_0  lag1_mean_1  lag1_mean_2  lag1_mean_3  lag1_mean_d_h2h1_0  \\\n",
       "0     -37.277174   -43.030969   -36.447629   -35.684127          -15.007371   \n",
       "1     -36.642161   -39.056745   -26.281063   -40.255439           -2.241697   \n",
       "2     -40.229463   -63.108915   -67.984208   -72.194004           -0.341225   \n",
       "3     -37.450039   -39.011419   -35.203550   -37.985609           -0.184593   \n",
       "4     -31.236584   -40.498620   -30.246655   -29.695176           -7.886850   \n",
       "..           ...          ...          ...          ...                 ...   \n",
       "643   -39.242498   -45.737576   -34.980090   -39.244412           18.515956   \n",
       "644   -24.606315   -33.268484   -29.241134   -28.847063           -5.959537   \n",
       "645   -26.876310   -35.773260   -25.528787   -26.643508           -0.760498   \n",
       "646   -25.517000   -37.471278   -27.008659   -26.074239            1.494077   \n",
       "647    -8.482512   -34.694453   -26.026519    -9.582047          -28.916717   \n",
       "\n",
       "     lag1_mean_d_h2h1_1  lag1_mean_d_h2h1_2  lag1_mean_d_h2h1_3  \\\n",
       "0             -1.645471            1.909458          -10.250657   \n",
       "1            -12.631036           -5.477559           12.076263   \n",
       "2              6.349947           -4.684524           22.157984   \n",
       "3             -2.599875           -2.107257           -4.667253   \n",
       "4              7.877147           -1.172290           -5.199914   \n",
       "..                  ...                 ...                 ...   \n",
       "643            9.856033           -0.110216           16.329277   \n",
       "644            4.258647           -0.051484           -4.038128   \n",
       "645           -0.923390           -3.411059            0.451387   \n",
       "646           -2.046352            0.591996           -0.201772   \n",
       "647            0.389423            3.632897          -26.254541   \n",
       "\n",
       "     lag1_mean_q1_0  lag1_mean_q1_1  ...  freq_669_3  freq_679_3  freq_689_3  \\\n",
       "0        -30.173763      -39.916087  ...    0.013639    0.014673    0.016323   \n",
       "1        -47.894014      -25.070973  ...    0.017032    0.020773    0.008015   \n",
       "2        -36.495415      -65.410248  ...    0.009989    0.024158    0.013508   \n",
       "3        -39.540556      -38.890191  ...    0.008634    0.020171    0.018735   \n",
       "4        -26.230491      -48.784865  ...    0.013128    0.017328    0.027893   \n",
       "..              ...             ...  ...         ...         ...         ...   \n",
       "643      -69.083018      -57.004967  ...    0.050628    0.051594    0.025037   \n",
       "644      -19.911037      -35.485516  ...    0.002609    0.009808    0.005097   \n",
       "645      -23.806253      -34.942615  ...    0.010003    0.015004    0.014943   \n",
       "646      -19.449005      -35.719971  ...    0.034118    0.019674    0.026596   \n",
       "647       25.596159      -36.627040  ...    0.010696    0.011209    0.009125   \n",
       "\n",
       "     freq_699_3  freq_709_3  freq_720_3  freq_730_3  freq_740_3  freq_750_3  \\\n",
       "0      0.010981    0.002892    0.007469    0.023877    0.006166    0.010377   \n",
       "1      0.026345    0.018926    0.030342    0.020967    0.011433    0.032048   \n",
       "2      0.020656    0.015429    0.009691    0.001305    0.013673    0.018705   \n",
       "3      0.008070    0.022522    0.025040    0.035756    0.017217    0.012021   \n",
       "4      0.026951    0.022054    0.015784    0.009199    0.018158    0.009810   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "643    0.012807    0.023609    0.005483    0.006116    0.007702    0.005607   \n",
       "644    0.003745    0.004550    0.003305    0.002596    0.002048    0.003165   \n",
       "645    0.014015    0.009935    0.010050    0.001803    0.008293    0.007048   \n",
       "646    0.030456    0.007588    0.017037    0.004276    0.013569    0.036147   \n",
       "647    0.002342    0.004840    0.003587    0.001920    0.005150    0.016070   \n",
       "\n",
       "     Label  \n",
       "0      1.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      1.0  \n",
       "4      2.0  \n",
       "..     ...  \n",
       "643    1.0  \n",
       "644    0.0  \n",
       "645    0.0  \n",
       "646    2.0  \n",
       "647    0.0  \n",
       "\n",
       "[648 rows x 989 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used the newly collected dataset of me (8/5) as subjectc-1 in minecraft-state folder\n",
    "filename = 'their-minecraft-state'\n",
    "\n",
    "outfile_path = os.getcwd() + '/dataset/training_dataset/' + filename + '.csv'\n",
    "\n",
    "df = pd.read_csv(outfile_path)\n",
    "print(df['Label'].value_counts())\n",
    "print('df shape: {}'.format(df.shape))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rrE0PAjkVRvZ"
   },
   "outputs": [],
   "source": [
    "def preprocess_inputs(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    y = df['Label'].copy()\n",
    "    X = df.drop('Label', axis=1).copy()\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.7, random_state=123)\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "X_train, X_val, y_train, y_val = preprocess_inputs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vy9zw2az55wp",
    "outputId": "847d0a06-0b5b-4dce-b1c5-dc40b6b69289"
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (gru/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b92282633322>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexpand_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;31m# GRU does not support constants. Ignore it during process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m       \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m       init_state = get_initial_state_fn(\n\u001b[0m\u001b[1;32m    643\u001b[0m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[1;32m    644\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[0;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1947\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state_for_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[0;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[1;32m   2985\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2986\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2987\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[0;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[1;32m   3003\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3004\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[0;34m(unnested_state_size)\u001b[0m\n\u001b[1;32m   2998\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2999\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3000\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3002\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2818\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2819\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2820\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2821\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   2866\u001b[0m           \u001b[0;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2867\u001b[0m           \u001b[0;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2868\u001b[0;31m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2869\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2870\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[0;34m(value, shape, dtype, name)\u001b[0m\n\u001b[1;32m   2802\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2803\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2804\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2805\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2806\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   3028\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m     \"\"\"\n\u001b[0;32m-> 3030\u001b[0;31m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[1;32m   3031\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[1;32m   3032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (gru/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "\n",
    "expand_dims = tf.expand_dims(inputs, axis=2)\n",
    "\n",
    "rnn = tf.keras.layers.GRU(1024, return_sequences=True)(expand_dims)\n",
    "\n",
    "dense = tf.keras.layers.Dense(256, activation='relu')(rnn)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(dense)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(3, activation='softmax')(flatten)\n",
    "''' With the updated data, where \"Stationary\" state is added, change # of units to 4 from 3 '''\n",
    "# outputs = tf.keras.layers.Dense(4, activation='softmax')(flatten)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ljSUzsZJw3x8",
    "outputId": "50be201c-b282-4dfb-b862-206187dc186a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - 12s 311ms/step - loss: 3.0752 - accuracy: 0.4790 - val_loss: 1.2066 - val_accuracy: 0.4103\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 4s 284ms/step - loss: 0.6862 - accuracy: 0.6689 - val_loss: 0.3680 - val_accuracy: 0.8103\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.3526 - accuracy: 0.8433 - val_loss: 0.4301 - val_accuracy: 0.7795\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.2125 - accuracy: 0.9205 - val_loss: 0.2753 - val_accuracy: 0.8769\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.0771 - accuracy: 0.9823 - val_loss: 0.2272 - val_accuracy: 0.9026\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.0457 - accuracy: 0.9890 - val_loss: 0.2231 - val_accuracy: 0.9282\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.0484 - accuracy: 0.9823 - val_loss: 0.3120 - val_accuracy: 0.8974\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.1092 - accuracy: 0.9514 - val_loss: 0.3174 - val_accuracy: 0.8974\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.0313 - accuracy: 0.9934 - val_loss: 0.1472 - val_accuracy: 0.9333\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1448 - val_accuracy: 0.9538\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9538\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1611 - val_accuracy: 0.9333\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1687 - val_accuracy: 0.9487\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 4s 294ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9487\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 6.0439e-04 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9487\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 4s 295ms/step - loss: 5.0487e-04 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9487\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 4.3793e-04 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9538\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 3.9340e-04 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 0.9538\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 4s 297ms/step - loss: 3.5664e-04 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9538\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 4s 297ms/step - loss: 3.3009e-04 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9538\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 3.0355e-04 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9487\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 4s 299ms/step - loss: 2.8007e-04 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9487\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 4s 301ms/step - loss: 2.6833e-04 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9487\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 4s 300ms/step - loss: 2.3833e-04 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9487\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 4s 301ms/step - loss: 2.2396e-04 - accuracy: 1.0000 - val_loss: 0.1397 - val_accuracy: 0.9487\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 4s 303ms/step - loss: 2.1277e-04 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9487\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 4s 302ms/step - loss: 1.9544e-04 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9487\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 4s 303ms/step - loss: 1.8165e-04 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9487\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 5s 304ms/step - loss: 1.7143e-04 - accuracy: 1.0000 - val_loss: 0.1386 - val_accuracy: 0.9487\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 5s 304ms/step - loss: 1.6052e-04 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 0.9487\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 5s 304ms/step - loss: 1.5438e-04 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 0.9487\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 1.4258e-04 - accuracy: 1.0000 - val_loss: 0.1373 - val_accuracy: 0.9487\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 1.3573e-04 - accuracy: 1.0000 - val_loss: 0.1377 - val_accuracy: 0.9487\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 1.2934e-04 - accuracy: 1.0000 - val_loss: 0.1369 - val_accuracy: 0.9487\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 1.2358e-04 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9487\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 5s 307ms/step - loss: 1.1624e-04 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 0.9487\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 1.0968e-04 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9538\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 5s 308ms/step - loss: 1.0692e-04 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9487\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 5s 308ms/step - loss: 9.8895e-05 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9487\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 5s 310ms/step - loss: 9.4249e-05 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 0.9487\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 5s 309ms/step - loss: 8.9931e-05 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9487\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 5s 309ms/step - loss: 8.4978e-05 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9487\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 5s 309ms/step - loss: 8.1376e-05 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9538\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 5s 310ms/step - loss: 7.7150e-05 - accuracy: 1.0000 - val_loss: 0.1325 - val_accuracy: 0.9538\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 5s 310ms/step - loss: 7.3989e-05 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9538\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 5s 310ms/step - loss: 7.0102e-05 - accuracy: 1.0000 - val_loss: 0.1313 - val_accuracy: 0.9487\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 6.6834e-05 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9487\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 5s 310ms/step - loss: 6.4117e-05 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9538\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 6.1300e-05 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9538\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 5.8836e-05 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9487\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 5s 312ms/step - loss: 5.6063e-05 - accuracy: 1.0000 - val_loss: 0.1311 - val_accuracy: 0.9538\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 5.5373e-05 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9538\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 5.1534e-05 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9538\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 4.8724e-05 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9538\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 4.6955e-05 - accuracy: 1.0000 - val_loss: 0.1304 - val_accuracy: 0.9538\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.6437e-05 - accuracy: 1.0000 - val_loss: 0.1285 - val_accuracy: 0.9487\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.3133e-05 - accuracy: 1.0000 - val_loss: 0.1302 - val_accuracy: 0.9538\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.1341e-05 - accuracy: 1.0000 - val_loss: 0.1296 - val_accuracy: 0.9538\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.9963e-05 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9538\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.8611e-05 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9538\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 3.7304e-05 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9538\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.5840e-05 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9538\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.4815e-05 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9538\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.3175e-05 - accuracy: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9538\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.2170e-05 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9538\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.1401e-05 - accuracy: 1.0000 - val_loss: 0.1280 - val_accuracy: 0.9538\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 3.0232e-05 - accuracy: 1.0000 - val_loss: 0.1268 - val_accuracy: 0.9538\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.9523e-05 - accuracy: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9538\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.8338e-05 - accuracy: 1.0000 - val_loss: 0.1283 - val_accuracy: 0.9538\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.7525e-05 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 0.9538\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.6566e-05 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9538\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.5821e-05 - accuracy: 1.0000 - val_loss: 0.1263 - val_accuracy: 0.9538\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.4845e-05 - accuracy: 1.0000 - val_loss: 0.1274 - val_accuracy: 0.9590\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.4375e-05 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9538\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.3413e-05 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9590\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.3062e-05 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9590\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.2172e-05 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9590\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.1588e-05 - accuracy: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9590\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.0946e-05 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 0.9590\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.0116e-05 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9590\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.9626e-05 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9590\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.8888e-05 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9590\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.8547e-05 - accuracy: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9590\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.8417e-05 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9590\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.7489e-05 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9590\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.6810e-05 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9590\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.6453e-05 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 0.9590\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.6161e-05 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9590\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.5454e-05 - accuracy: 1.0000 - val_loss: 0.1249 - val_accuracy: 0.9590\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.5268e-05 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9590\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.4684e-05 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9641\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 1.4384e-05 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9641\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.4380e-05 - accuracy: 1.0000 - val_loss: 0.1266 - val_accuracy: 0.9590\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.3653e-05 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9641\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.3430e-05 - accuracy: 1.0000 - val_loss: 0.1252 - val_accuracy: 0.9590\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.2893e-05 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9590\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.2651e-05 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9641\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.2335e-05 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9590\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.1983e-05 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9590\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.1671e-05 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9641\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.1469e-05 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9641\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.1176e-05 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9590\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 1.1037e-05 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9641\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.0763e-05 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9590\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.0452e-05 - accuracy: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9641\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.0201e-05 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9641\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 1.0041e-05 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9641\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 9.8849e-06 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9641\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 9.6289e-06 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9641\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 9.4310e-06 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9641\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 9.2297e-06 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9641\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 9.0071e-06 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9641\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 8.8952e-06 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9641\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 8.6797e-06 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9692\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 8.5274e-06 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9692\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 8.3616e-06 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9692\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 8.1863e-06 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9692\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 8.0508e-06 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9692\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 7.9503e-06 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9692\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 7.8516e-06 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9692\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 7.5971e-06 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9692\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 7.5519e-06 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9692\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 7.3356e-06 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9692\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 7.2450e-06 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9641\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 7.2185e-06 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9692\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 6.9527e-06 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9692\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 6.8143e-06 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9692\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 6.6911e-06 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9692\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 6.6219e-06 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9692\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 6.4419e-06 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9692\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 6.3588e-06 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9692\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 6.2346e-06 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9692\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 6.1548e-06 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9692\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 6.1809e-06 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9692\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 5.8301e-06 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9692\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 5.9143e-06 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9692\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 5.7380e-06 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9692\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 5.6154e-06 - accuracy: 1.0000 - val_loss: 0.1219 - val_accuracy: 0.9692\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 5.5738e-06 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9692\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 5.4359e-06 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9692\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 5.3543e-06 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9692\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 5.2538e-06 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9692\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 5.1796e-06 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9692\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 5.0717e-06 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9692\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 5.0286e-06 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9692\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 5.0449e-06 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9692\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.8491e-06 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9692\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.8141e-06 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9692\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 4.7052e-06 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9692\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.6423e-06 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9692\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.5649e-06 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9692\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.5054e-06 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9692\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.4625e-06 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9692\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 4.3828e-06 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9692\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 4.3067e-06 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9692\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.2373e-06 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9692\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.1541e-06 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9692\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.1175e-06 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9692\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 4.0744e-06 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9692\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.9749e-06 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9692\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.9257e-06 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9692\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.8418e-06 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9692\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.8573e-06 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9744\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.7544e-06 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9692\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.7062e-06 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9692\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.6262e-06 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9692\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.5783e-06 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9692\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.5386e-06 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9692\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 3.4849e-06 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9692\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.4441e-06 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9692\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.3923e-06 - accuracy: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9692\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.4323e-06 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9692\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.3234e-06 - accuracy: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9744\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.2426e-06 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9692\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.1897e-06 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9692\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 3.1520e-06 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9692\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.1197e-06 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9692\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.1026e-06 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9692\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 3.0384e-06 - accuracy: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9692\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.9920e-06 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9744\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.9726e-06 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9692\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.9263e-06 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9692\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.8868e-06 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9744\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.8523e-06 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9744\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.8202e-06 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9744\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.7726e-06 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9744\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.7918e-06 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9744\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.7244e-06 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9692\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.6744e-06 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9692\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 2.6352e-06 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9744\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.6100e-06 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9744\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.5271e-06 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9692\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.5707e-06 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9692\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.4981e-06 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9744\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 2.4792e-06 - accuracy: 1.0000 - val_loss: 0.1198 - val_accuracy: 0.9744\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.4373e-06 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9744\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.4031e-06 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9744\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.3784e-06 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9744\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 2.3465e-06 - accuracy: 1.0000 - val_loss: 0.1202 - val_accuracy: 0.9744\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 2.3568e-06 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9744\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200\n",
    ")\n",
    "model.save(os.getcwd() + '/drive/My Drive/their-gru_1024_dense_256_200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "XcrlSb709EaV",
    "outputId": "9f20c057-a2a3-4b66-b730-c6a092b3245c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "MJK0abaR4LeX",
    "outputId": "2bed08b8-b343-4fea-d3f0-46cfdaacc373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.436%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "----------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   WANDERING       0.98      0.96      0.97        67\n",
      "      MINING       1.00      0.99      0.99        69\n",
      "    BUILDING       0.94      0.98      0.96        59\n",
      "\n",
      "    accuracy                           0.97       195\n",
      "   macro avg       0.97      0.97      0.97       195\n",
      "weighted avg       0.98      0.97      0.97       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_acc = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "print(\"Test Accuracy: {:.3f}%\".format(model_acc * 100))\n",
    "\n",
    "label_mapping = {'WANDERING': 0, 'MINING': 1, 'BUILDING': 2}\n",
    "y_pred = np.array(list(map(lambda x: np.argmax(x), model.predict(X_val))))\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "clr = classification_report(y_val, y_pred, target_names=label_mapping.keys())\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True, vmin=0, fmt='g', cbar=False, cmap='Blues')\n",
    "plt.xticks(np.arange(3) + 0.5, label_mapping.keys())\n",
    "plt.yticks(np.arange(3) + 0.5, label_mapping.keys())\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_gru.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
